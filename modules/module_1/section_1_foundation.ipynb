{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1, Section 1: Foundation Concepts\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "- Understand how LLMs interact with external data through tools\n",
    "- Learn the fundamental building blocks: messages, tools, and tool calling\n",
    "- See the manual tool calling loop in action\n",
    "- Understand why agent abstractions are useful\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this section, we'll build a simple customer support system for TechHub, a fictional e-commerce electronics store. We'll start with the basics:\n",
    "1. How to make LLM calls with messages\n",
    "2. How to define tools that access external data (our TechHub database)\n",
    "3. The manual tool calling loop (involved but educational!)\n",
    "\n",
    "By the end, you'll understand **why** agent frameworks exist - spoiler, they automate the tedious parts we're about to implement manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's load our environment variables (API keys).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic LLM Call\n",
    "\n",
    "Let's start simple - just calling an LLM with a message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Framework for building applications with language models.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Configure model - change this to use different providers!\n",
    "# Examples: \"openai:gpt-4o-mini\", \"anthropic:claude-sonnet-4-5\"\n",
    "MODEL = \"anthropic:claude-haiku-4-5\"\n",
    "\n",
    "# Initialize the model\n",
    "llm = init_chat_model(MODEL)\n",
    "\n",
    "# Simple string input\n",
    "response = llm.invoke(\"What is LangChain in under 10 words?\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with Messages\n",
    "\n",
    "LLMs work with **messages** that have roles:\n",
    "- `SystemMessage`: Instructions for how the LLM should behave\n",
    "- `HumanMessage`: User input\n",
    "- `AIMessage`: Model responses\n",
    "- `ToolMessage`: Results from tool execution (we'll see this soon!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'd be happy to help you check on your order! However, I don't have access to our order tracking system right now.\n",
      "\n",
      "To get the status of order **ORD-2024-0123**, I recommend:\n",
      "\n",
      "1. **Check your email** - You should have received order confirmation and shipping updates there\n",
      "2. **Visit our website** - Log into your account and check the \"Orders\" or \"Order History\" section\n",
      "3. **Contact our support team directly** - They can look up your order with your order number and provide detailed status information\n",
      "\n",
      "Is there anything else I can help you with, or would you like information about a specific product?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Multi-turn conversation with messages\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful customer support assistant for TechHub, an electronics store.\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Hello!\"),\n",
    "    AIMessage(content=\"Hi! How can I help you today?\"),\n",
    "    HumanMessage(content=\"What's the status of order ORD-2024-0123?\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice the problem:** The LLM can't actually look up the order! It doesn't have access to our database.\n",
    "\n",
    "This is where **tools** come in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining Tools\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../../static/db_tools.png\" alt=\"Schema Diagram\">\n",
    "</div>\n",
    "\n",
    "Tools give LLMs the ability to interact with external systems. Let's create three simple tools that query our TechHub database.\n",
    "\n",
    "The `@tool` decorator automatically:\n",
    "- Extracts the function signature for the LLM\n",
    "- Uses the docstring as the tool description\n",
    "- Handles the input/output formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Path to our TechHub database\n",
    "DB_PATH = Path(\"../../data/structured/techhub.db\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_order_status(order_id: str) -> str:\n",
    "    \"\"\"Look up the status of an order by order ID.\n",
    "\n",
    "    Args:\n",
    "        order_id: The order ID (e.g., \"ORD-2024-0123\")\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with order status, shipped date, and tracking number.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = f\"SELECT status, shipped_date, tracking_number FROM orders WHERE order_id = '{order_id}'\"\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if not result:\n",
    "        return f\"No order found with ID: {order_id}\"\n",
    "\n",
    "    status, shipped_date, tracking = result\n",
    "    return f\"Order {order_id}: Status={status}, Shipped={shipped_date or 'Not yet shipped'}, Tracking={tracking or 'N/A'}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_product_price(product_name: str) -> str:\n",
    "    \"\"\"Get the current price of a product by name.\n",
    "\n",
    "    Args:\n",
    "        product_name: Product name to search for (e.g., \"MacBook Air\")\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with product name, price, and stock status.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = (\n",
    "        f\"SELECT name, price, in_stock FROM products WHERE name LIKE '%{product_name}%'\"\n",
    "    )\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if not result:\n",
    "        return f\"No product found matching: {product_name}\"\n",
    "\n",
    "    name, price, in_stock = result\n",
    "    stock_status = \"In Stock\" if in_stock else \"Out of Stock\"\n",
    "    return f\"{name}: ${price:.2f} - {stock_status}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_order_items(order_id: str) -> str:\n",
    "    \"\"\"Get all items (products) that were purchased in a specific order.\n",
    "\n",
    "    Args:\n",
    "        order_id: The order ID (e.g., \"ORD-2024-0063\")\n",
    "\n",
    "    Returns:\n",
    "        Formatted list of products in the order with product IDs, names, and quantities.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT oi.product_id, p.name, oi.quantity, oi.price_per_unit\n",
    "        FROM order_items oi\n",
    "        JOIN products p ON oi.product_id = p.product_id\n",
    "        WHERE oi.order_id = '{order_id}'\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    if not results:\n",
    "        return f\"No items found for order: {order_id}\"\n",
    "\n",
    "    items = []\n",
    "    for product_id, name, quantity, price in results:\n",
    "        items.append(f\"  • {name} (ID: {product_id}) - Qty: {quantity} @ ${price:.2f}\")\n",
    "\n",
    "    return f\"Items in order {order_id}:\\n\" + \"\\n\".join(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call of `get_product_price` tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MacBook Air M2 (13-inch, 256GB): $1199.00 - In Stock\n"
     ]
    }
   ],
   "source": [
    "example_product = \"MacBook Air\"\n",
    "result = get_product_price.invoke(example_product)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect how the `@tool` decorator parses the tool information into a `StructuredTool` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TOOL NAME ---\n",
      "get_product_price\n",
      "\n",
      "--- TOOL DESCRIPTION ---\n",
      "Get the current price of a product by name.\n",
      "\n",
      "Args:\n",
      "    product_name: Product name to search for (e.g., \"MacBook Air\")\n",
      "\n",
      "Returns:\n",
      "    Formatted string with product name, price, and stock status.\n",
      "\n",
      "--- TOOL ARGUMENTS ---\n",
      "{'product_name': {'title': 'Product Name', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- TOOL NAME ---\")\n",
    "print(get_product_price.name)\n",
    "print(\"\\n--- TOOL DESCRIPTION ---\")\n",
    "print(get_product_price.description)\n",
    "print(\"\\n--- TOOL ARGUMENTS ---\")\n",
    "print(get_product_price.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Manual Tool Calling Loop\n",
    "\n",
    "Now let's see how LLMs actually use tools! This happens in stages:\n",
    "\n",
    "1. **Give the LLM access to tools** - Bind tools so the LLM knows what's available\n",
    "2. **LLM decides when to call a tool** - Based on tool descriptions and the user's query\n",
    "3. **LLM formats the function call** - Returns which tool to call and with what arguments (but doesn't execute it!)\n",
    "4. **We manually execute the tool** - Run the actual function to get results\n",
    "5. **Pass results back to the LLM** - So it can use them to generate a final answer\n",
    "\n",
    "Let's see each stage in action!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Bind Tools to the Model\n",
    "\n",
    "First, we tell the LLM what tools are available by \"binding\" them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind tools to the model - this tells the LLM what tools are available\n",
    "tools = [get_order_status, get_product_price, get_order_items]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: LLM Decides to Call a Tool\n",
    "\n",
    "Now let's give the LLM a query. It will decide which tool to call based on the descriptions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'id': 'toolu_01FAG1tgAX9rCyLkUgwyGgMq', 'input': {'order_id': 'ORD-2024-0123'}, 'name': 'get_order_status', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  get_order_status (toolu_01FAG1tgAX9rCyLkUgwyGgMq)\n",
      " Call ID: toolu_01FAG1tgAX9rCyLkUgwyGgMq\n",
      "  Args:\n",
      "    order_id: ORD-2024-0123\n"
     ]
    }
   ],
   "source": [
    "# Ask about an order\n",
    "query = \"What's the status of order ORD-2024-0123?\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful customer support assistant.\"),\n",
    "    HumanMessage(content=query),\n",
    "]\n",
    "\n",
    "# Call the LLM\n",
    "response = llm_with_tools.invoke(messages)\n",
    "\n",
    "# Add the AI's tool call to messages\n",
    "messages.append(response)\n",
    "\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Manually Execute the Tool\n",
    "\n",
    "The LLM told us WHAT to call and WITH WHAT ARGUMENTS. Now **we** need to actually run the function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: get_order_status(**{'order_id': 'ORD-2024-0123'}) \n",
      "============================================================\n",
      "\n",
      "Tool Result: Order ORD-2024-0123: Status=Delivered, Shipped=2024-12-07, Tracking=1Z999AA113527782\n"
     ]
    }
   ],
   "source": [
    "# Extract the tool call information\n",
    "tool_call = response.tool_calls[0]\n",
    "tool_name = tool_call[\"name\"]\n",
    "tool_args = tool_call[\"args\"]\n",
    "\n",
    "print(f\"Executing: {tool_name}(**{tool_args})\", f\"\\n{'='*60}\\n\")\n",
    "\n",
    "# Manually execute the tool\n",
    "if tool_name == \"get_order_status\":\n",
    "    tool_result = get_order_status.invoke(tool_args)\n",
    "elif tool_name == \"get_product_price\":\n",
    "    tool_result = get_product_price.invoke(tool_args)\n",
    "elif tool_name == \"get_order_items\":\n",
    "    tool_result = get_order_items.invoke(tool_args)\n",
    "\n",
    "print(f\"Tool Result: {tool_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Pass Results Back to the LLM\n",
    "\n",
    "Now we need to send the tool's result back to the LLM so it can generate a final answer for the user. Note that we use a `ToolMessage` type when adding tool result details back to the message history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful customer support assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's the status of order ORD-2024-0123?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=[{'id': 'toolu_01FAG1tgAX9rCyLkUgwyGgMq', 'input': {'order_id': 'ORD-2024-0123'}, 'name': 'get_order_status', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01AfVZfGL7K6MYjn9CEyDufF', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 883, 'output_tokens': 66, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001', 'model_provider': 'anthropic'}, id='lc_run--d37d4945-8f35-4841-b04e-1f2760e709a0-0', tool_calls=[{'name': 'get_order_status', 'args': {'order_id': 'ORD-2024-0123'}, 'id': 'toolu_01FAG1tgAX9rCyLkUgwyGgMq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 883, 'output_tokens': 66, 'total_tokens': 949, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}),\n",
       " ToolMessage(content='Order ORD-2024-0123: Status=Delivered, Shipped=2024-12-07, Tracking=1Z999AA113527782', tool_call_id='toolu_01FAG1tgAX9rCyLkUgwyGgMq')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# Create a ToolMessage with the result\n",
    "tool_message = ToolMessage(\n",
    "    content=str(tool_result),\n",
    "    tool_call_id=tool_call[\"id\"],  # Must match the ID from the tool call\n",
    ")\n",
    "messages.append(tool_message)\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Get the Final Answer\n",
    "\n",
    "Now the LLM has the tool result and can give a complete answer to the user:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! Here's the status of your order:\n",
      "\n",
      "**Order ORD-2024-0123**\n",
      "- **Status:** Delivered\n",
      "- **Shipped Date:** December 7, 2024\n",
      "- **Tracking Number:** 1Z999AA113527782\n",
      "\n",
      "Your order has been delivered! If you need any other information about this order or have any questions, feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "# Call the LLM again with the tool result\n",
    "final_response = llm_with_tools.invoke(messages)\n",
    "\n",
    "final_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting It All Together: The Loop\n",
    "\n",
    "In real scenarios, the LLM might need to call multiple tools or loop several times. Let's create a function that automates this process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_loop(user_query: str):\n",
    "    \"\"\"Run the complete tool calling loop.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful customer support assistant for TechHub.\"\n",
    "        ),\n",
    "        HumanMessage(content=user_query),\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"User: {user_query}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Keep looping until we get a final answer\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        iteration += 1\n",
    "\n",
    "        # Call the LLM\n",
    "        response = llm_with_tools.invoke(messages)\n",
    "\n",
    "        # Check if LLM wants to use tools\n",
    "        if not response.tool_calls:\n",
    "            # No tools needed - we have the final answer!\n",
    "            print(f\"Final Answer: {response.content}\\n\")\n",
    "            break\n",
    "\n",
    "        # LLM wants to use tools\n",
    "        print(\n",
    "            f\"[Iteration {iteration}] LLM is calling {len(response.tool_calls)} tool(s)...\"\n",
    "        )\n",
    "        messages.append(response)\n",
    "\n",
    "        # Execute each tool\n",
    "        for tool_call in response.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool_args = tool_call[\"args\"]\n",
    "\n",
    "            # Execute the tool\n",
    "            if tool_name == \"get_order_status\":\n",
    "                result = get_order_status.invoke(tool_args)\n",
    "            elif tool_name == \"get_product_price\":\n",
    "                result = get_product_price.invoke(tool_args)\n",
    "            elif tool_name == \"get_order_items\":\n",
    "                result = get_order_items.invoke(tool_args)\n",
    "\n",
    "            print(f\"  → {tool_name}({list(tool_args.values())[0]}) = {result[:50]}...\")\n",
    "\n",
    "            # Add tool result to messages\n",
    "            messages.append(\n",
    "                ToolMessage(content=str(result), tool_call_id=tool_call[\"id\"])\n",
    "            )\n",
    "\n",
    "        print()  # Blank line before next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try It Out!\n",
    "\n",
    "Now let's test our agent loop with different queries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1: Simple order lookup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User: What's the status of order ORD-2024-0123?\n",
      "============================================================\n",
      "\n",
      "[Iteration 1] LLM is calling 1 tool(s)...\n",
      "  → get_order_status(ORD-2024-0123) = Order ORD-2024-0123: Status=Delivered, Shipped=202...\n",
      "\n",
      "Final Answer: Your order **ORD-2024-0123** has been **delivered**! Here are the details:\n",
      "\n",
      "- **Status:** Delivered\n",
      "- **Shipped Date:** December 7, 2024\n",
      "- **Tracking Number:** 1Z999AA113527782\n",
      "\n",
      "Is there anything else you'd like to know about this order?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent_loop(\"What's the status of order ORD-2024-0123?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2: Product price lookup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User: How much does the MacBook Air cost?\n",
      "============================================================\n",
      "\n",
      "[Iteration 1] LLM is calling 1 tool(s)...\n",
      "  → get_product_price(MacBook Air) = MacBook Air M2 (13-inch, 256GB): $1199.00 - In Sto...\n",
      "\n",
      "Final Answer: The **MacBook Air M2 (13-inch, 256GB)** is currently priced at **$1,199.00** and is in stock. Would you like to know anything else about this product or place an order?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent_loop(\"How much does the MacBook Air cost?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3: Multiple tools in one query**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User: What's the status of order ORD-2024-0123 and how much does a MacBook Air cost?\n",
      "============================================================\n",
      "\n",
      "[Iteration 1] LLM is calling 2 tool(s)...\n",
      "  → get_order_status(ORD-2024-0123) = Order ORD-2024-0123: Status=Delivered, Shipped=202...\n",
      "  → get_product_price(MacBook Air) = MacBook Air M2 (13-inch, 256GB): $1199.00 - In Sto...\n",
      "\n",
      "Final Answer: Great! Here's the information you requested:\n",
      "\n",
      "**Order Status for ORD-2024-0123:**\n",
      "- **Status:** Delivered\n",
      "- **Shipped Date:** December 7, 2024\n",
      "- **Tracking Number:** 1Z999AA113527782\n",
      "\n",
      "**MacBook Air Price:**\n",
      "- **Product:** MacBook Air M2 (13-inch, 256GB)\n",
      "- **Price:** $1,199.00\n",
      "- **Stock Status:** In Stock\n",
      "\n",
      "Is there anything else you'd like to know about your order or our products?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent_loop(\n",
    "    \"What's the status of order ORD-2024-0123 and how much does a MacBook Air cost?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **LLMs can't access external data** without tools\n",
    "2. **Tools are functions** with clear schemas (name, description, arguments)\n",
    "3. **The tool calling loop** is: LLM → tool call → execute → result → LLM → repeat until done\n",
    "4. **This is tedious!** We had to:\n",
    "   - Manually check for tool calls\n",
    "   - Execute each tool ourselves\n",
    "   - Format and append results\n",
    "   - Manage the loop logic\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Understanding the manual loop is crucial because:\n",
    "- **Every agent framework does this** under the hood\n",
    "- You can debug agent behavior by understanding what's happening\n",
    "- You'll appreciate the abstractions in Section 2!\n",
    "\n",
    "### What's Next\n",
    "\n",
    "In **Section 2**, we'll replace all this manual code with `create_agent` - a simple abstraction that:\n",
    "- Handles the tool calling loop automatically\n",
    "- Adds memory (conversation history)\n",
    "- Supports streaming responses\n",
    "- Requires just a few lines of code!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
