{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1, Section 1: Foundation Concepts\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "- Understand how LLMs interact with external data through tools\n",
    "- Learn the fundamental building blocks: messages, tools, and tool calling\n",
    "- See the manual tool calling loop in action\n",
    "- Understand why we need agent abstractions (sets up Section 2)\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this section, we'll build a simple customer support system for TechHub, an e-commerce electronics store. We'll start with the basics:\n",
    "1. How to make LLM calls with messages\n",
    "2. How to define tools that access external data (our database)\n",
    "3. The manual tool calling loop (tedious but educational!)\n",
    "\n",
    "By the end, you'll understand **why** agent frameworks exist - they automate the tedious parts we're about to implement manually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's load our environment variables (API keys).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic LLM Call\n",
    "\n",
    "Let's start simple - just calling an LLM with a message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangChain is a framework for developing applications powered by language models that simplifies the process of chaining together multiple LLM calls and integrating them with external data sources and tools.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Configure model - change this to use different providers!\n",
    "# Examples: \"openai:gpt-4o-mini\", \"anthropic:claude-sonnet-4-5\"\n",
    "MODEL = \"anthropic:claude-haiku-4-5\"\n",
    "\n",
    "# Initialize the model\n",
    "llm = init_chat_model(MODEL)\n",
    "\n",
    "# Simple string input\n",
    "response = llm.invoke(\"What is LangChain in one sentence?\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with Messages\n",
    "\n",
    "LLMs work with **messages** that have roles:\n",
    "- `SystemMessage`: Instructions/context for the LLM\n",
    "- `HumanMessage`: User input\n",
    "- `AIMessage`: LLM responses\n",
    "- `ToolMessage`: Results from tool execution (we'll see this soon!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'd be happy to help you check on that order! However, I don't have access to our order management system or customer account information.\n",
      "\n",
      "To get the status of order **ORD-2024-0123**, I'd recommend:\n",
      "\n",
      "1. **Check your email** - You should have received order confirmation and tracking emails\n",
      "2. **Visit our website** - Log into your TechHub account and go to \"My Orders\" to see real-time status\n",
      "3. **Call our support team** - They can look up your order with your order number and verify details\n",
      "4. **Live chat with an agent** - Available on our website during business hours\n",
      "\n",
      "Is there anything else I can help you with, or would you like information about our products and services?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Multi-turn conversation with messages\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful customer support assistant for TechHub, an electronics store.\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Hello!\"),\n",
    "    AIMessage(content=\"Hi! How can I help you today?\"),\n",
    "    HumanMessage(content=\"What's the status of order ORD-2024-0123?\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice the problem:** The LLM can't actually look up the order! It doesn't have access to our database.\n",
    "\n",
    "This is where **tools** come in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining Tools\n",
    "\n",
    "Tools give LLMs the ability to interact with external systems. Let's create two simple tools that query our TechHub database.\n",
    "\n",
    "The `@tool` decorator automatically:\n",
    "- Extracts the function signature for the LLM\n",
    "- Uses the docstring as the tool description\n",
    "- Handles the input/output formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Path to our TechHub database\n",
    "DB_PATH = Path(\"../../data/structured/techhub.db\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_order_status(order_id: str) -> str:\n",
    "    \"\"\"Look up the status of an order by order ID.\n",
    "\n",
    "    Args:\n",
    "        order_id: The order ID (e.g., \"ORD-2024-0123\")\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with order status, shipped date, and tracking number.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = f\"SELECT status, shipped_date, tracking_number FROM orders WHERE order_id = '{order_id}'\"\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if not result:\n",
    "        return f\"No order found with ID: {order_id}\"\n",
    "\n",
    "    status, shipped_date, tracking = result\n",
    "    return f\"Order {order_id}: Status={status}, Shipped={shipped_date or 'Not yet shipped'}, Tracking={tracking or 'N/A'}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_product_price(product_name: str) -> str:\n",
    "    \"\"\"Get the current price of a product by name.\n",
    "\n",
    "    Args:\n",
    "        product_name: Product name to search for (e.g., \"MacBook Air\")\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with product name, price, and stock status.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = (\n",
    "        f\"SELECT name, price, in_stock FROM products WHERE name LIKE '%{product_name}%'\"\n",
    "    )\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if not result:\n",
    "        return f\"No product found matching: {product_name}\"\n",
    "\n",
    "    name, price, in_stock = result\n",
    "    stock_status = \"In Stock\" if in_stock else \"Out of Stock\"\n",
    "    return f\"{name}: ${price:.2f} - {stock_status}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call of `get_product_price` tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MacBook Air M2 (13-inch, 256GB): $1199.00 - In Stock\n"
     ]
    }
   ],
   "source": [
    "example_product = \"MacBook Air\"\n",
    "result = get_product_price.invoke(example_product)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect how the `@tool` decorator parses the tool information into a `StructuredTool` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TOOL NAME ---\n",
      "get_product_price\n",
      "\n",
      "--- TOOL DESCRIPTION ---\n",
      "Get the current price of a product by name.\n",
      "\n",
      "Args:\n",
      "    product_name: Product name to search for (e.g., \"MacBook Air\")\n",
      "\n",
      "Returns:\n",
      "    Formatted string with product name, price, and stock status.\n",
      "\n",
      "--- TOOL ARGUMENTS ---\n",
      "{'product_name': {'title': 'Product Name', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- TOOL NAME ---\")\n",
    "print(get_product_price.name)\n",
    "print(\"\\n--- TOOL DESCRIPTION ---\")\n",
    "print(get_product_price.description)\n",
    "print(\"\\n--- TOOL ARGUMENTS ---\")\n",
    "print(get_product_price.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Manual Tool Calling Loop\n",
    "\n",
    "Now let's see how LLMs actually use tools! This happens in stages:\n",
    "\n",
    "1. **Give the LLM access to tools** - Bind tools so the LLM knows what's available\n",
    "2. **LLM decides when to call a tool** - Based on tool descriptions and the user's query\n",
    "3. **LLM formats the function call** - Returns which tool to call and with what arguments (but doesn't execute it!)\n",
    "4. **We manually execute the tool** - Run the actual function to get results\n",
    "5. **Pass results back to the LLM** - So it can use them to generate a final answer\n",
    "\n",
    "Let's see each stage in action!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Bind Tools to the Model\n",
    "\n",
    "First, we tell the LLM what tools are available by \"binding\" them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind tools to the model - this tells the LLM what tools are available\n",
    "tools = [get_order_status, get_product_price]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: LLM Decides to Call a Tool\n",
    "\n",
    "Now let's give the LLM a query. It will decide which tool to call based on the descriptions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'id': 'toolu_018zoVrJU8iLDWMqvUE6sjNw', 'input': {'order_id': 'ORD-2024-0123'}, 'name': 'get_order_status', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  get_order_status (toolu_018zoVrJU8iLDWMqvUE6sjNw)\n",
      " Call ID: toolu_018zoVrJU8iLDWMqvUE6sjNw\n",
      "  Args:\n",
      "    order_id: ORD-2024-0123\n"
     ]
    }
   ],
   "source": [
    "# Ask about an order\n",
    "query = \"What's the status of order ORD-2024-0123?\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful customer support assistant.\"),\n",
    "    HumanMessage(content=query),\n",
    "]\n",
    "\n",
    "# Call the LLM\n",
    "response = llm_with_tools.invoke(messages)\n",
    "\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Manually Execute the Tool\n",
    "\n",
    "The LLM told us WHAT to call and WITH WHAT ARGUMENTS. Now **we** need to actually run the function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: get_order_status(**{'order_id': 'ORD-2024-0123'})\n",
      "============================================================\n",
      "\n",
      "Tool Result: Order ORD-2024-0123: Status=Delivered, Shipped=2024-12-07, Tracking=1Z999AA113527782\n"
     ]
    }
   ],
   "source": [
    "# Extract the tool call information\n",
    "tool_call = response.tool_calls[0]\n",
    "tool_name = tool_call[\"name\"]\n",
    "tool_args = tool_call[\"args\"]\n",
    "\n",
    "print(f\"Executing: {tool_name}(**{tool_args})\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Manually execute the tool\n",
    "if tool_name == \"get_order_status\":\n",
    "    tool_result = get_order_status.invoke(tool_args)\n",
    "elif tool_name == \"get_product_price\":\n",
    "    tool_result = get_product_price.invoke(tool_args)\n",
    "\n",
    "print(f\"Tool Result: {tool_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Pass Results Back to the LLM\n",
    "\n",
    "Now we need to send the tool's result back to the LLM so it can generate a final answer for the user. Note that we use a `ToolMessage` type when adding tool result details back to the message history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful customer support assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's the status of order ORD-2024-0123?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=[{'id': 'toolu_018zoVrJU8iLDWMqvUE6sjNw', 'input': {'order_id': 'ORD-2024-0123'}, 'name': 'get_order_status', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01BSWheZ68JdgZqMdbEcxVJb', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 758, 'output_tokens': 66, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001', 'model_provider': 'anthropic'}, id='lc_run--44a9e7ac-b860-41dd-af9b-9b6153f59626-0', tool_calls=[{'name': 'get_order_status', 'args': {'order_id': 'ORD-2024-0123'}, 'id': 'toolu_018zoVrJU8iLDWMqvUE6sjNw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 758, 'output_tokens': 66, 'total_tokens': 824, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}),\n",
       " ToolMessage(content='Order ORD-2024-0123: Status=Delivered, Shipped=2024-12-07, Tracking=1Z999AA113527782', tool_call_id='toolu_018zoVrJU8iLDWMqvUE6sjNw')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# Add the AI's tool call to messages\n",
    "messages.append(response)\n",
    "\n",
    "# Create a ToolMessage with the result\n",
    "tool_message = ToolMessage(\n",
    "    content=str(tool_result),\n",
    "    tool_call_id=tool_call[\"id\"],  # Must match the ID from the tool call\n",
    ")\n",
    "messages.append(tool_message)\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Get the Final Answer\n",
    "\n",
    "Now the LLM has the tool result and can give a complete answer to the user:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! Here's the status of your order:\n",
      "\n",
      "**Order ID:** ORD-2024-0123\n",
      "- **Status:** Delivered ✓\n",
      "- **Shipped Date:** December 7, 2024\n",
      "- **Tracking Number:** 1Z999AA113527782\n",
      "\n",
      "Your order has been successfully delivered! If you need any further assistance or have questions about your delivery, feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "# Call the LLM again with the tool result\n",
    "final_response = llm_with_tools.invoke(messages)\n",
    "\n",
    "final_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting It All Together: The Loop\n",
    "\n",
    "In real scenarios, the LLM might need to call multiple tools or loop several times. Let's create a function that automates this process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "def run_agent_loop(user_query: str):\n",
    "    \"\"\"Run the complete tool calling loop.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful customer support assistant for TechHub.\"\n",
    "        ),\n",
    "        HumanMessage(content=user_query),\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"User: {user_query}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Keep looping until we get a final answer\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        iteration += 1\n",
    "\n",
    "        # Call the LLM\n",
    "        response = llm_with_tools.invoke(messages)\n",
    "\n",
    "        # Check if LLM wants to use tools\n",
    "        if not response.tool_calls:\n",
    "            # No tools needed - we have the final answer!\n",
    "            print(f\"Final Answer: {response.content}\\n\")\n",
    "            break\n",
    "\n",
    "        # LLM wants to use tools\n",
    "        print(\n",
    "            f\"[Iteration {iteration}] LLM is calling {len(response.tool_calls)} tool(s)...\"\n",
    "        )\n",
    "        messages.append(response)\n",
    "\n",
    "        # Execute each tool\n",
    "        for tool_call in response.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool_args = tool_call[\"args\"]\n",
    "\n",
    "            # Execute the tool\n",
    "            if tool_name == \"get_order_status\":\n",
    "                result = get_order_status.invoke(tool_args)\n",
    "            elif tool_name == \"get_product_price\":\n",
    "                result = get_product_price.invoke(tool_args)\n",
    "\n",
    "            print(f\"  → {tool_name}({list(tool_args.values())[0]}) = {result[:50]}...\")\n",
    "\n",
    "            # Add tool result to messages\n",
    "            messages.append(\n",
    "                ToolMessage(content=str(result), tool_call_id=tool_call[\"id\"])\n",
    "            )\n",
    "\n",
    "        print()  # Blank line before next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try It Out!\n",
    "\n",
    "Now let's test our agent loop with different queries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1: Simple order lookup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User: What's the status of order ORD-2024-0123?\n",
      "============================================================\n",
      "\n",
      "[Iteration 1] LLM is calling 1 tool(s)...\n",
      "  → get_order_status(ORD-2024-0123) = Order ORD-2024-0123: Status=Delivered, Shipped=202...\n",
      "\n",
      "Final Answer: Great news! Here's the status of your order:\n",
      "\n",
      "**Order ID:** ORD-2024-0123\n",
      "- **Status:** Delivered\n",
      "- **Shipped Date:** December 7, 2024\n",
      "- **Tracking Number:** 1Z999AA113527782\n",
      "\n",
      "Your order has been successfully delivered. If you have any other questions or need further assistance, feel free to ask!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent_loop(\"What's the status of order ORD-2024-0123?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2: Product price lookup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User: How much does the MacBook Air cost?\n",
      "============================================================\n",
      "\n",
      "[Iteration 1] LLM is calling 1 tool(s)...\n",
      "  → get_product_price(MacBook Air) = MacBook Air M2 (13-inch, 256GB): $1199.00 - In Sto...\n",
      "\n",
      "Final Answer: The **MacBook Air M2 (13-inch, 256GB)** is currently priced at **$1,199.00** and is **in stock**. \n",
      "\n",
      "Is there anything else you'd like to know about this product or any other items from TechHub?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent_loop(\"How much does the MacBook Air cost?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3: Multiple tools in one query**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User: What's the status of order ORD-2024-0123 and how much does a MacBook Air cost?\n",
      "============================================================\n",
      "\n",
      "[Iteration 1] LLM is calling 2 tool(s)...\n",
      "  → get_order_status(ORD-2024-0123) = Order ORD-2024-0123: Status=Delivered, Shipped=202...\n",
      "  → get_product_price(MacBook Air) = MacBook Air M2 (13-inch, 256GB): $1199.00 - In Sto...\n",
      "\n",
      "Final Answer: Great! Here's the information you requested:\n",
      "\n",
      "**Order Status (ORD-2024-0123):**\n",
      "- **Status:** Delivered\n",
      "- **Shipped Date:** December 7, 2024\n",
      "- **Tracking Number:** 1Z999AA113527782\n",
      "\n",
      "**MacBook Air Price:**\n",
      "- **Product:** MacBook Air M2 (13-inch, 256GB)\n",
      "- **Price:** $1,199.00\n",
      "- **Stock Status:** In Stock\n",
      "\n",
      "Your order has already been delivered! If you have any other questions about your order or would like to purchase a MacBook Air, feel free to let me know!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent_loop(\n",
    "    \"What's the status of order ORD-2024-0123 and how much does a MacBook Air cost?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **LLMs can't access external data** without tools\n",
    "2. **Tools are functions** with clear schemas (name, description, arguments)\n",
    "3. **The tool calling loop** is: LLM → tool call → execute → result → LLM → repeat until done\n",
    "4. **This is tedious!** We had to:\n",
    "   - Manually check for tool calls\n",
    "   - Execute each tool ourselves\n",
    "   - Format and append results\n",
    "   - Manage the loop logic\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Understanding the manual loop is crucial because:\n",
    "- **Every agent framework does this** under the hood\n",
    "- You can debug agent behavior by understanding what's happening\n",
    "- You'll appreciate the abstractions in Section 2!\n",
    "\n",
    "### What's Next\n",
    "\n",
    "In **Section 2**, we'll replace all this manual code with `create_agent` - a simple abstraction that:\n",
    "- Handles the tool calling loop automatically\n",
    "- Adds memory (conversation history)\n",
    "- Supports streaming responses\n",
    "- Requires just a few lines of code!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
